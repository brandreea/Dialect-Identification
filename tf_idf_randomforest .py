# -*- coding: utf-8 -*-
"""Tf-idf+randomforest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sSv6PdX8qLbqyForMT6Z2l6fTCmKVCzj
"""

import pandas as pd
import numpy as np
import nltk
from nltk.corpus import stopwords
from sklearn import svm
from sklearn import preprocessing
from sklearn.metrics import accuracy_score
import math

#Aceste randuri sunt pentru montarea drive-ului. In cazul in care rulati local, le puteti comenta.
from google.colab import drive
drive.mount('/content/drive')

from sklearn.metrics import f1_score
from sklearn.svm import SVC

#citirea etichetelor
 #a se seta calea
 train_labels = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ml-2020-unibuc-3/train_labels.txt', sep='\t',header=None)
 test_labels = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ml-2020-unibuc-3/validation_labels.txt', sep='\t',header=None)
print(train_labels[1])

#a se seta calea
#citirea datelor de antrenare
with open('/content/drive/My Drive/Colab Notebooks/ml-2020-unibuc-3/train_samples.txt', encoding='utf-8') as q:
    train_data = q.readlines()
print(train_data[0])

#separarea id-urilor de text
train_ids=[]
train_text=[]
for data in train_data:
  id,text=data.split('\t')
  train_ids.append(id)
  train_text.append(text)
print(train_text[0])

#a se seta calea din drive
#citirea datelor de validare
with open('/content/drive/My Drive/Colab Notebooks/ml-2020-unibuc-3/validation_samples.txt', encoding='utf-8') as q:
    test_data = q.readlines()
print(test_data[0])

#separarea id-ului de text
test_ids=[]
test_texts=[]

for data in test_data:
  id,text=data.split('\t')
  test_ids.append(id)
  test_texts.append(text)
print(test_texts[0])

#crearea listelor de  etichete
train_label=[c for c in train_labels[1].values]

test_label=np.array([c for c in test_labels[1].values])

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

#definim modelul
#pastram toate caracterele, mai putin spatiile si caracterele tip blank
randForest_pipe = Pipeline([
 ('tvec', TfidfVectorizer(norm='l2', token_pattern='\\S*', analyzer='word',lowercase=False)),
 ('rf', RandomForestClassifier())
])
randForest_pipe.fit(train_text, train_label)

#definim parametri pe care vrem sa ii testam pentru RandomForest
randForest_params = {
 'rf__n_estimators': [200, 500, 700],
 'rf__max_depth': [50,110, 700,1000],
 'rf__min_samples_split': [100,50,70],
 'rf__max_leaf_nodes': [None]
}
randForest_cls = GridSearchCV(rf_pipe, param_grid=rf_params, cv = 5, verbose = 1, n_jobs = -1)
randForest_cls.fit(train_text,train_label)

pred=randForest_cls.predict(test_texts)
print(f1_score(test_label,pred,average='macro'), accuracy_score(test_label,pred))
print(randForest_cls.best_params_)

from sklearn.metrics import confusion_matrix
print(confusion_matrix(test_label,pred))

#citirea datelor de testare
with open('/content/drive/My Drive/Colab Notebooks/ml-2020-unibuc-3/test_samples.txt', encoding='utf-8') as q:
    final_data = q.readlines()
print(final_data[0])
#separarea
final_ids=[]
final_texts=[]
for data in final_data:
  id,text=data.split('\t')
  final_ids.append(id)
  final_texts.append(text)
print(final_texts[0])

final_pred=rf_gs.predict(final_texts)

print(final_pred)

import csv
#scrierea fisierului
with open('/content/drive/My Drive/Colab Notebooks/innovatorsnn-cript-svm.csv', 'w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(["id", "label"])
    count=0
    for i in range(len(final_pred)):
         p=0
         if(final_pred[i][0]>final_pred[i][1]):
           p=0
         else: p=1
         writer.writerow([final_ids[i], p])
    print(count)