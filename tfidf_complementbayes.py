# -*- coding: utf-8 -*-
"""Tfidf+ComplementBayes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EIPIDUNWBhNU0mixq8I5ShOeK-2xWWag
"""

import pandas as pd
import numpy as np
import nltk
from nltk.corpus import stopwords
from sklearn import svm
from sklearn import preprocessing
from sklearn.metrics import accuracy_score
import math

#Aceste randuri sunt pentru montarea drive-ului. In cazul in care rulati local, le puteti comenta.
from google.colab import drive
drive.mount('/content/drive')

from sklearn.metrics import f1_score
from sklearn.svm import SVC

#citirea etichetelor
 #a se seta calea
 train_labels = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ml-2020-unibuc-3/train_labels.txt', sep='\t',header=None)
 test_labels = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ml-2020-unibuc-3/validation_labels.txt', sep='\t',header=None)
print(train_labels[1])

#a se seta calea
#citirea datelor de antrenare
with open('/content/drive/My Drive/Colab Notebooks/ml-2020-unibuc-3/train_samples.txt', encoding='utf-8') as q:
    train_data = q.readlines()
print(train_data[0])

#separarea id-urilor de text
train_ids=[]
train_texts=[]

for data in train_data:
  id,text=data.split('\t')
  train_ids.append(id)
  train_texts.append(text)
print(train_texts[0])

#a se seta calea din drive
#citirea datelor de validare
with open('/content/drive/My Drive/Colab Notebooks/ml-2020-unibuc-3/validation_samples.txt', encoding='utf-8') as q:
    test_data = q.readlines()
print(test_data[0])

#separarea id-ului de text
test_ids=[]
test_texts=[]

for data in test_data:
  id,text=data.split('\t')
  test_ids.append(id)
  test_texts.append(text)
print(test_texts[0])

#crearea listelor de  etichete
train_label=[c for c in train_labels[1].values]


test_label=np.array([c for c in test_labels[1].values])




from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import ComplementNB

#definim modelul
#pastram toate caracterele, mai putin spatiile si caracterele tip blank
ComplementNB_pipe = Pipeline([
 ('tvec', TfidfVectorizer(norm='l2', token_pattern='\\S*', analyzer='word',lowercase=False)),
 ('nb', ComplementNB())
])
ComplementNB_pipe.fit(train_texts, train_label)

#definim parametri pe care vrem sa ii testam pentru ComplementNB
ComplementNB_params = {
 'nb__alpha':[0.1,0.01, 0.02,0.03,0.04,0.05,0.001]
}
#crearea feature-urilor
ComplementNB_cls=GridSearchCV(ComplementNB_pipe, param_grid=ComplementNB_params, cv = 5, verbose = 1, n_jobs = -1)
ComplementNB_cls.fit(train_texts, train_label)



pred=ComplementNB_cls.predict(test_texts)
print(f1_score(test_label, pred, average='macro'), accuracy_score(test_label,pred))
print(ComplementNB_cls.best_params_)

from sklearn.metrics import confusion_matrix
print(confusion_matrix(test_label,pred))

#citirea datelor ce trebuie prezise
#a se insera calea
with open('/content/drive/My Drive/Colab Notebooks/ml-2020-unibuc-3/test_samples.txt', encoding='utf-8') as q:
    final_data = q.readlines()
print(final_data[0])
final_ids=[]
final_texts=[]
for data in final_data:
  id,text=data.split('\t')
  final_ids.append(id)
  final_texts.append(text)
print(final_texts[0])

final_pred=ComplementNB_cls.predict_proba(final_texts)

import csv
with open('/content/drive/My Drive/Colab Notebooks/innovatorsnn-cript-svm.csv', 'w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(["id", "label"])
    count=0
    for i in range(len(final_pred)):
         p=0
         if(final_pred[i][0]>final_pred[i][1]):
           p=0
         else: p=1
         writer.writerow([final_ids[i], p])
    print(count)

